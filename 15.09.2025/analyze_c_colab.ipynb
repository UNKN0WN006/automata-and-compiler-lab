{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4e9afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PLY (only needed in fresh Colab runtimes)\n",
    "try:\n",
    "    import ply.lex as lex\n",
    "    import ply.yacc as yacc\n",
    "    print('PLY already installed')\n",
    "except Exception:\n",
    "    import sys\n",
    "    !{sys.executable} -m pip install ply --quiet\n",
    "    import ply.lex as lex\n",
    "    import ply.yacc as yacc\n",
    "    print('Installed PLY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b616e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLY Lexer for a subset of C\n",
    "import re\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import ply.lex as lex\n",
    "\n",
    "# Reserved keywords mapping to token names\n",
    "reserved = {\n",
    "    'continue': 'CONTINUE', 'default': 'DEFAULT', 'do': 'DO', 'double': 'DOUBLE', 'else': 'ELSE',\n",
    "    'if': 'IF', 'int': 'INT', 'long': 'LONG', 'register': 'REGISTER', 'return': 'RETURN',\n",
    "    'switch': 'SWITCH', 'typedef': 'TYPEDEF', 'union': 'UNION', 'unsigned': 'UNSIGNED', 'void': 'VOID',\n",
    "] + list(set(reserved.values()))\n",
    "\n",
    "# Single-character literals are handled via `literals` so we can keep code concise\n",
    "literals = ['+','-','*','/','%','=','<','>','!','&','|','^','~',',',';','(',')','{','}','[',']']\n",
    "\n",
    "# Regex rules for multi-character tokens (longer patterns first)\n",
    "t_PLUSPLUS = r'\\+\\+'\n",
    "t_MINUSMINUS = r'--'\n",
    "t_EQ = r'=='\n",
    "t_NE = r'!='\n",
    "t_LE = r'<='\n",
    "t_GE = r'>='\n",
    "t_ANDAND = r'&&'\n",
    "t_OROR = r'\\|\\|'\n",
    "t_LSHIFT = r'<<'\n",
    "t_RSHIFT = r'>>'\n",
    "\n",
    "# Preprocessor (e.g., #include <...>)\n",
    "def t_PREPROCESSOR(t):\n",
    "    r'.*'\n",
    "    # capture special characters like < and > in preprocessor lines\n",
    "    return t\n",
    "\n",
    "# String literal (handles simple escaped chars)\n",
    "def t_STRING(t):\n",
    "    r'\"([^\\\\\n",
    "]|(\\\\.))*?\"'\n",
    "    return t\n",
    "\n",
    "# Number constant (integers for now)\n",
    "def t_NUMBER(t):\n",
    "    r'\\b\\d+\\b'\n",
    "    t.value = int(t.value)\n",
    "    return t\n",
    "\n",
    "# Identifier (and check for reserved keywords)\n",
    "def t_ID(t):\n",
    "    r'\\b[_a-zA-Z][_a-zA-Z0-9]*\\b'\n",
    "    val = t.value\n",
    "    if val in reserved:\n",
    "        t.type = reserved[val]\n",
    "    return t\n",
    "\n",
    "# Ignore spaces and tabs\n",
    "t_ignore = ' \t'\n",
    "\n",
    "# Track line numbers\n",
    "def t_newline(t):\n",
    "    r'\\n+'\n",
    "    t.lexer.lineno += t.value.count('\n",
    "')\n",
    "\n",
    "# Error handling for illegal characters - we'll collect them\n",
    "lexical_errors = []\n",
    "def t_error(t):\n",
    "    lexical_errors.append((t.value[0], t.lineno))\n",
    "    t.lexer.skip(1)\n",
    "\n",
    "# Build the lexer\n",
    "lexer = lex.lex()\n",
    "\n",
    "# Helper: classify single-character tokens into separators/operators/special chars\n",
    "SEPARATORS = set([',',';','(',')','{','}','[',']'])\n",
    "OPERATOR_CHARS = set(['+','-','*','/','%','=','<','>','!','&','|','^','~'])\n",
    "SPECIAL_CHARS = set(['#','<','>'])\n",
    "\n",
    "def analyze_code_with_lexer(code):\n",
    "    # reset\n",
    "    global lexical_errors\n",
    "    lexical_errors = []\n",
    "    lexer.input(code)\n",
    "    symbol_table = defaultdict(set)\n",
    "    token_count = 0\n",
    "    token_list = []\n",
    "    while True:\n",
    "        tok = lexer.token()\n",
    "        if not tok:\n",
    "            break\n",
    "        token_count += 1\n",
    "        token_list.append(tok)\n",
    "        # categorize token into symbol table buckets similar to original script\n",
    "        t = tok.type\n",
    "        v = tok.value\n",
    "        if t in reserved.values():\n",
    "            symbol_table['Keyword'].add(v)\n",
    "        elif t == 'ID':\n",
    "            symbol_table['Identifier'].add(v)\n",
    "        elif t == 'NUMBER':\n",
    "            symbol_table['Constant'].add(str(v))\n",
    "        elif t == 'STRING':\n",
    "            symbol_table['Constant'].add(v)\n",
    "        elif t == 'PREPROCESSOR':\n",
    "            symbol_table['Special Character'].add('#')\n",
    "            # also capture < and > if present in includes\n",
    "            if '<' in v or '>' in v:\n",
    "                symbol_table['Special Character'].update([c for c in v if c in SPECIAL_CHARS])\n",
    "        elif t in ('PLUSPLUS','MINUSMINUS','EQ','NE','LE','GE','ANDAND','OROR','LSHIFT','RSHIFT'):\n",
    "            symbol_table['Operator'].add(tok.value)\n",
    "        else:\n",
    "            # if token is a single-char literal, classify accordingly\n",
    "            sval = str(v)\n",
    "            if len(sval) == 1 and sval in SEPARATORS:\n",
    "                symbol_table['Separator'].add(sval)\n",
    "            elif len(sval) == 1 and sval in OPERATOR_CHARS:\n",
    "                symbol_table['Operator'].add(sval)\n",
    "            else:\n",
    "                # unknown categories fall back to listing as lexical error if not whitespace\n",
    "                pass\n",
    "    return token_list, token_count, symbol_table, lexical_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d14665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple PLY Yacc grammar for a small subset of C (function definitions, declarations, basic statements)\n",
    "import ply.yacc as yacc\n",
    "\n",
    "# precedence (a small subset)\n",
    "precedence = (\n",
    ",\n",
    ",\n",
    "\n",
    "def p_program(p):\n",
    "    '''program : external_declaration_list'''\n",
    "    p[0] = ('program', p[1])\n",
    "\n",
    "def p_external_declaration_list(p):\n",
    "    '''external_declaration_list : external_declaration_list external_declaration\n",
    "                               | external_declaration'''\n",
    "    if len(p) == 3:\n",
    "        if isinstance(p[1], list):\n",
    "            p[0] = p[1] + [p[2]]\n",
    "        else:\n",
    "            p[0] = [p[1], p[2]]\n",
    "    else:\n",
    "        p[0] = [p[1]]\n",
    "\n",
    "def p_external_declaration(p):\n",
    "    '''external_declaration : function_definition\n",
    "                          | declaration'''\n",
    "    p[0] = p[1]\n",
    "\n",
    "def p_function_definition(p):\n",
    "    '''function_definition : type_specifier ID '(' parameter_list_opt ')' compound_statement'''\n",
    "    p[0] = ('func', p[1], p[2], p[4], p[6])\n",
    "\n",
    "def p_parameter_list_opt(p):\n",
    "    '''parameter_list_opt : parameter_list\n",
    "                         | empty'''\n",
    "    p[0] = p[1]\n",
    "\n",
    "def p_parameter_list(p):\n",
    "    '''parameter_list : parameter_list ',' parameter\n",
    "                     | parameter'''\n",
    "    if len(p) == 4:\n",
    "        p[0] = p[1] + [p[3]]\n",
    "    else:\n",
    "        p[0] = [p[1]]\n",
    "\n",
    "def p_parameter(p):\n",
    "    'parameter : type_specifier ID'\n",
    "    p[0] = (p[1], p[2])\n",
    "\n",
    "def p_declaration(p):\n",
    "    '''declaration : type_specifier init_declarator_list ';'\n",
    "                   | type_specifier ';' '''\n",
    "    if len(p) == 4:\n",
    "        p[0] = ('decl', p[1], p[2])\n",
    "    else:\n",
    "        p[0] = ('decl', p[1], [])\n",
    "\n",
    "def p_init_declarator_list(p):\n",
    "    '''init_declarator_list : init_declarator_list ',' init_declarator\n",
    "                            | init_declarator'''\n",
    "    if len(p) == 4:\n",
    "        p[0] = p[1] + [p[3]]\n",
    "    else:\n",
    "        p[0] = [p[1]]\n",
    "\n",
    "def p_init_declarator(p):\n",
    "    '''init_declarator : ID\n",
    "                    | ID '=' expression'''\n",
    "    if len(p) == 2:\n",
    "        p[0] = (p[1], None)\n",
    "    else:\n",
    "        p[0] = (p[1], p[3])\n",
    "\n",
    "def p_type_specifier(p):\n",
    "    '''type_specifier : INT\n",
    "                      | CHAR\n",
    "                      | VOID\n",
    "                      | FLOAT\n",
    "                      | DOUBLE\n",
    "                      | UNSIGNED\n",
    "                      | LONG\n",
    "                      | SHORT'''\n",
    "    p[0] = p[1]\n",
    "\n",
    "def p_compound_statement(p):\n",
    "    'compound_statement : '{' statement_list_opt '}' '\n",
    ",\n",
    "\n",
    "2\n",
    ",\n",
    ","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d763a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6b5747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf22162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b85dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894a3551",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
